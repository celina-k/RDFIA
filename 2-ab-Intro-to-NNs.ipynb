{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"2-ab-Intro-to-NNs_Cel.ipynb","provenance":[{"file_id":"1rDdcBxXhqI3AZjCFdDaJxChaIUoFqeGn","timestamp":1634739064678},{"file_id":"13wk-uH95GeGB0W5MU7RHRDf1PE8fzEag","timestamp":1603810050900}],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"PbzBJ1m9FBBb"},"source":["# Warning : \n","# Do \"File -> Save a copy in Drive\" before you start modifying the notebook, otherwise your modifications will not be saved.\n"]},{"cell_type":"code","metadata":{"id":"NfnKy8NB8J5e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635082018629,"user_tz":-120,"elapsed":2128,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}},"outputId":"3eb70dd2-c770-4dec-e818-0701ebab07ff"},"source":["!wget http://webia.lip6.fr/~dancette/deep-learning/assets/TP3-4/TP3-4.zip\n","!unzip -j TP3-4.zip"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-10-24 13:26:56--  http://webia.lip6.fr/~dancette/deep-learning/assets/TP3-4/TP3-4.zip\n","Resolving webia.lip6.fr (webia.lip6.fr)... 132.227.201.33\n","Connecting to webia.lip6.fr (webia.lip6.fr)|132.227.201.33|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13421167 (13M) [application/zip]\n","Saving to: ‘TP3-4.zip’\n","\n","TP3-4.zip           100%[===================>]  12.80M  11.1MB/s    in 1.2s    \n","\n","2021-10-24 13:26:57 (11.1 MB/s) - ‘TP3-4.zip’ saved [13421167/13421167]\n","\n","Archive:  TP3-4.zip\n","  inflating: tme5.py                 \n","  inflating: mnist.mat               \n","  inflating: circles.py              \n","  inflating: circles.mat             \n"]}]},{"cell_type":"code","metadata":{"id":"2vQ_LLdx8J5b","executionInfo":{"status":"ok","timestamp":1635082071052,"user_tz":-120,"elapsed":26732,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}}},"source":["import math\n","import torch\n","from torch.autograd import Variable\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%run 'tme5.py'"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"48x_ha7f8J5i"},"source":["# Part 1 : Forward and backward passes \"by hands\""]},{"cell_type":"code","metadata":{"id":"GtizX1JV8J5n","executionInfo":{"status":"ok","timestamp":1635082198200,"user_tz":-120,"elapsed":248,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}}},"source":["def init_params(nx, nh, ny):\n","    \"\"\"\n","    nx, nh, ny: integers\n","    out params: dictionnary\n","    \"\"\"\n","    params = {}\n","    \n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # fill values for Wh, Wy, bh, by\n","    \n","    #params[\"Wh\"] = torch.normal(0, 0.3, size=(nh, nx))\n","    #params[\"Wy\"] = torch.normal(0, 0.3, size=(ny, nh))\n","    params[\"Wh\"] = torch.randn(nh,nx)\n","    params[\"Wy\"] = torch.randn(ny,nh)\n","    params[\"bh\"] = torch.randn(nh)\n","    params[\"by\"] = torch.randn(ny)\n","\n","    ####################\n","    ##      END        #\n","    ####################\n","    return params"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"mRgxR0_pWDEy","executionInfo":{"status":"ok","timestamp":1635082078381,"user_tz":-120,"elapsed":212,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}}},"source":["def softmax(X):\n","    # sortie en batch d'== d\n","    s = torch.sum(torch.exp(X),dim = 1) \n","    s = s.view(-1, 1)\n","    res = torch.exp(X)/s\n","    return res"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"jk-N_Ny67yo-","executionInfo":{"status":"ok","timestamp":1635082080107,"user_tz":-120,"elapsed":194,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}}},"source":["def forward(params, X):\n","    \"\"\"\n","    params: dictionnary\n","    X: (n_batch, dimension)\n","    \"\"\"\n","    bsize = X.size(0)\n","    nh = params['Wh'].size(0)\n","    ny = params['Wy'].size(0)\n","    outputs = {}\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # fill values for X, htilde, h, ytilde, yhat\n","    \n","    outputs[\"X\"] = X\n","    outputs[\"htilde\"] = torch.mm(outputs[\"X\"], params[\"Wh\"].T) + params[\"bh\"]\n","    outputs[\"h\"] = torch.tanh(outputs[\"htilde\"])\n","    outputs[\"ytilde\"] = torch.mm(outputs[\"h\"], params[\"Wy\"].T) + params[\"by\"]\n","    outputs[\"yhat\"] = softmax(outputs[\"ytilde\"])\n","    \n","    ####################\n","    ##      END        #\n","    ####################\n","\n","    return outputs['yhat'], outputs"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"-uB0A2b28NZK","executionInfo":{"status":"ok","timestamp":1635082082124,"user_tz":-120,"elapsed":183,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}}},"source":["def loss_accuracy(Yhat, Y):\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","\n","    L = -torch.mean(torch.sum(Y*torch.log(Yhat)))\n","    _, indsY = torch.max (Y, 1)\n","    _, indsYhat = torch.max (Yhat, 1)\n","    acc=torch.where(indsY==indsYhat,1,0).sum()/Y.shape[0]\n","   \n","    ####################\n","    ##      END        #\n","    ####################\n","\n","    return L, acc"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"WWJjdiFe8qi5","executionInfo":{"status":"ok","timestamp":1635082083843,"user_tz":-120,"elapsed":177,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}}},"source":["def backward(params, outputs, Y):\n","    bsize = Y.shape[0]\n","    grads = {}\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # fill values for Wy, Wh, by, bh\n","\n","    grad_Ytilde = (outputs['yhat']-Y)/bsize\n","    grad_Htilde = (torch.mm(grad_Ytilde, params['Wy'])*(1-outputs[\"h\"]))/bsize\n","    grads[\"Wy\"] = (torch.mm(grad_Ytilde.T, outputs[\"h\"]))/bsize\n","    grads[\"Wh\"] = (torch.mm(grad_Htilde.T,outputs['X']))/bsize\n","    grads[\"by\"] = (torch.sum(grad_Ytilde, dim=0).T)\n","    grads[\"bh\"] = (torch.sum(grad_Htilde, dim=0).T)\n","    \n","    ####################\n","    ##      END        #\n","    ####################\n","    return grads"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"nAnsISsW9CnH","executionInfo":{"status":"ok","timestamp":1635082085543,"user_tz":-120,"elapsed":241,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}}},"source":["def sgd(params, grads, eta):\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # update the params values\n","\n","    params[\"Wh\"] -=  eta * grads['Wh']\n","    params[\"Wy\"] -=  eta * grads['Wy']\n","    params[\"bh\"] -=  eta * grads['bh']\n","    params[\"by\"] -=  eta * grads['by']\n","\n","    ####################\n","    ##      END        #\n","    ####################\n","    return params"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hifuW5UFA3DZ"},"source":["## Global learning procedure \"by hands\""]},{"cell_type":"code","metadata":{"id":"4RSw6bd0-qUe","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1U_kYv3ykpz4Fovqgm4mfidbTq-eqB1Kw"},"executionInfo":{"status":"ok","timestamp":1635082247136,"user_tz":-120,"elapsed":42763,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}},"outputId":"fdae2e11-9df9-4994-a818-d257030e7a5d"},"source":["# init\n","data = CirclesData()\n","data.plot_data()\n","N = data.Xtrain.shape[0]\n","Nbatch = 10\n","nx = data.Xtrain.shape[1]\n","nh = 10\n","ny = data.Ytrain.shape[1]\n","eta = 0.03\n","\n","params = init_params(nx, nh, ny)\n","\n","curves = [[],[], [], []]\n","\n","# epoch\n","for iteration in range(150):\n","\n","    # permute\n","    perm = np.random.permutation(N)\n","    Xtrain = data.Xtrain[perm, :]\n","    Ytrain = data.Ytrain[perm, :]\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # batches\n","    for j in range(N // Nbatch):\n","\n","        indsBatch = range(j * Nbatch, (j+1) * Nbatch)\n","        X = Xtrain[indsBatch, :]\n","        Y = Ytrain[indsBatch, :]\n","\n","        # write the optimization algorithm on the batch (X,Y)\n","        # using the functions: forward, loss_accuracy, backward, sgd\n","        Yhat, outputs = forward(params, X)\n","        loss, acc = loss_accuracy(Yhat, Y)\n","        grads = backward (params, outputs, Y)\n","        params = sgd(params, grads, eta)\n","\n","    ####################\n","    ##      END        #\n","    ####################\n","\n","    Yhat_train, _ = forward(params, data.Xtrain)\n","    Yhat_test, _ = forward(params, data.Xtest)\n","    Ltrain, acctrain = loss_accuracy(Yhat_train, data.Ytrain)\n","    Ltest, acctest = loss_accuracy(Yhat_test, data.Ytest)\n","    Ygrid, _ = forward(params, data.Xgrid)  \n","\n","    title = 'Iter {}: Acc train {:.1f}% ({:.2f}), acc test {:.1f}% ({:.2f})'.format(iteration, acctrain, Ltrain, acctest, Ltest)\n","    print(title)\n","    data.plot_data_with_grid(Ygrid, title)\n","\n","    curves[0].append(acctrain)\n","    curves[1].append(acctest)\n","    curves[2].append(Ltrain)\n","    curves[3].append(Ltest)\n","\n","fig = plt.figure()\n","plt.plot(curves[0], label=\"acc. train\")\n","plt.plot(curves[1], label=\"acc. test\")\n","plt.plot(curves[2], label=\"loss train\")\n","plt.plot(curves[3], label=\"loss test\")\n","plt.legend()\n","plt.show()"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"OrHHH5PL8J54"},"source":["# Part 2 : Simplification of the backward pass with `torch.autograd`\n","\n"]},{"cell_type":"code","metadata":{"id":"7G4q5zP0CEvB","executionInfo":{"status":"ok","timestamp":1635082434208,"user_tz":-120,"elapsed":6,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}}},"source":["def init_params(nx, nh, ny):\n","    \"\"\"\n","    nx, nh, ny: integers\n","    out params: dictionnary\n","    \"\"\"\n","    params = {}\n","    \n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # fill values for Wh, Wy, bh, by\n","    # activaye autograd on the network weights\n","    \n","    params[\"Wh\"] = torch.normal(0, 0.3, size=(nh, nx), requires_grad=True)\n","    params[\"Wy\"] = torch.normal(0, 0.3, size=(ny, nh), requires_grad=True)\n","    params[\"bh\"] = torch.randn(nh, requires_grad=True)\n","    params[\"by\"] = torch.randn(ny, requires_grad=True)\n","\n","    ####################\n","    ##      END        #\n","    ####################\n","    return params"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZL0tSjpKCyVB"},"source":["The function `forward` remains unchanged from previous part. \n","\n","The function `backward` is no longer used because of \"autograd\". "]},{"cell_type":"code","metadata":{"id":"hA4ycHlfBzCK","executionInfo":{"status":"ok","timestamp":1635082436069,"user_tz":-120,"elapsed":227,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}}},"source":["def sgd(params, eta):\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # update the network weights\n","    # warning: use torch.no_grad()\n","    # and reset to zero the gradient accumulators\n","\n","    with torch.no_grad() :\n","      params[\"Wh\"] -= eta * params[\"Wh\"].grad\n","      params[\"Wy\"] -= eta * params[\"Wy\"].grad\n","      params[\"bh\"] -= eta * params[\"bh\"].grad\n","      params[\"by\"] -= eta * params[\"by\"].grad  \n","      params['Wh'].grad.zero_()  \n","      params['Wy'].grad.zero_()\n","      params['bh'].grad.zero_()\n","      params['by'].grad.zero_()\n","\n","    ####################\n","    ##      END        #\n","    ####################\n","    return params"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rjgcmgQpDfOb"},"source":["## Global learning procedure with autograd"]},{"cell_type":"code","metadata":{"id":"8p5oR3EqDea-","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1cchmiBv_rtRqYQSQOFlNQCxd3ERW-wcy"},"executionInfo":{"status":"ok","timestamp":1635082479236,"user_tz":-120,"elapsed":41788,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}},"outputId":"01f11426-6e58-4f90-e988-d4cce11d161a"},"source":["# init\n","data = CirclesData()\n","data.plot_data()\n","N = data.Xtrain.shape[0]\n","Nbatch = 10\n","nx = data.Xtrain.shape[1]\n","nh = 10\n","ny = data.Ytrain.shape[1]\n","eta = 0.03\n","\n","params = init_params(nx, nh, ny)\n","\n","curves = [[],[], [], []]\n","\n","# epoch\n","for iteration in range(150):\n","\n","    # permute\n","    perm = np.random.permutation(N)\n","    Xtrain = data.Xtrain[perm, :]\n","    Ytrain = data.Ytrain[perm, :]\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # batches\n","    for j in range(N // Nbatch):\n","\n","        indsBatch = range(j * Nbatch, (j+1) * Nbatch)\n","        X = Xtrain[indsBatch, :]\n","        Y = Ytrain[indsBatch, :]\n","\n","  \n","        # write the optimization algorithm on the batch (X,Y)\n","        # using the functions: forward, loss_accuracy, sgd\n","        # and the backward function with autograd\n","\n","\n","        Yhat, outputs = forward(params, X)\n","        loss, acc = loss_accuracy(Yhat, Y)\n","        loss.backward()\n","        params = sgd(params, eta)\n","        \n","\n","    ####################\n","    ##      END        #\n","    ####################\n","\n","\n","    Yhat_train, _ = forward(params, data.Xtrain)\n","    Yhat_test, _ = forward(params, data.Xtest)\n","    Ltrain, acctrain = loss_accuracy(Yhat_train, data.Ytrain)\n","    Ltest, acctest = loss_accuracy(Yhat_test, data.Ytest)\n","    Ygrid, _ = forward(params, data.Xgrid)  \n","\n","    title = 'Iter {}: Acc train {:.1f}% ({:.2f}), acc test {:.1f}% ({:.2f})'.format(iteration, acctrain, Ltrain, acctest, Ltest)\n","    print(title)\n","    # detach() is used to remove the predictions from the computational graph in autograd\n","    data.plot_data_with_grid(Ygrid.detach(), title)\n","\n","    curves[0].append(acctrain)\n","    curves[1].append(acctest)\n","    curves[2].append(Ltrain)\n","    curves[3].append(Ltest)\n","\n","fig = plt.figure()\n","plt.plot(curves[0], label=\"acc. train\")\n","plt.plot(curves[1], label=\"acc. test\")\n","plt.plot(curves[2], label=\"loss train\")\n","plt.plot(curves[3], label=\"loss test\")\n","plt.legend()\n","plt.show()"],"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"5FV1iss68J6H"},"source":["# Part 3 : Simplification of the forward pass with `torch.nn`"]},{"cell_type":"markdown","metadata":{"id":"x6T5Uq7JEl47"},"source":["`init_params` and `forward` are replaced by the `init_model` function which defines the network architecture and the loss."]},{"cell_type":"code","metadata":{"id":"5-h4r-FH8J6I","executionInfo":{"status":"ok","timestamp":1635090696377,"user_tz":-120,"elapsed":206,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}}},"source":["def init_model(nx, nh, ny):\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","\n","    model = torch.nn.Sequential(\n","        torch.nn.Linear(nx, nh),\n","        torch.nn.Tanh(),\n","        torch.nn.Linear(nh, ny)#,\n","        #torch.nn.Softmax()\n","    )\n","    loss = torch.nn.CrossEntropyLoss()\n","\n","    ####################\n","    ##      END        #\n","    ####################\n","\n","    return model, loss"],"execution_count":110,"outputs":[]},{"cell_type":"code","metadata":{"id":"geE_TI96FXnl","executionInfo":{"status":"ok","timestamp":1635090689795,"user_tz":-120,"elapsed":199,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}}},"source":["def loss_accuracy(loss, Yhat, Y):\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # call the loss function\n","\n","      Y_ = torch.max(Y,1)[1]\n","      L = loss(Yhat,Y_)\n","    _, indsY = torch.max (Y, 1)\n","    _, indsYhat = torch.max (Yhat, 1)\n","    acc=torch.where(indsY==indsYhat,1,0).sum()/Y.shape[0]\n","\n","    ####################\n","    ##      END        #\n","    ####################\n","\n","    return L, acc"],"execution_count":109,"outputs":[]},{"cell_type":"code","metadata":{"id":"e93bvFiYGKnA","executionInfo":{"status":"ok","timestamp":1635090665155,"user_tz":-120,"elapsed":180,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}}},"source":["def sgd(model, eta):\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # update the network weights\n","    # warning: use torch.no_grad()\n","    # and reset to zero the gradient accumulators\n","    with torch.no_grad():\n","      for param in model.parameters():\n","        param -= eta * param.grad\n","      model.zero_grad()\n","\n","    ####################\n","    ##      END        #\n","    ####################\n","    return model"],"execution_count":107,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aOxBMmD4Gxtp"},"source":["## Global learning procedure with autograd and `torch.nn`"]},{"cell_type":"code","metadata":{"id":"4hMBmCNvHCLn","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1_dwL7p5M22Y4F3dq_nepU7TO63PP4xQv"},"executionInfo":{"status":"ok","timestamp":1635090743073,"user_tz":-120,"elapsed":44352,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}},"outputId":"a08d96bb-dd87-423b-89cf-84654761d7f1"},"source":["# init\n","data = CirclesData()\n","data.plot_data()\n","N = data.Xtrain.shape[0]\n","Nbatch = 10\n","nx = data.Xtrain.shape[1]\n","nh = 10\n","ny = data.Ytrain.shape[1]\n","eta = 0.03\n","\n","model, loss = init_model(nx, nh, ny)\n","\n","curves = [[],[], [], []]\n","\n","# epoch\n","for iteration in range(150):\n","\n","    # permute\n","    perm = np.random.permutation(N)\n","    Xtrain = data.Xtrain[perm, :]\n","    Ytrain = data.Ytrain[perm, :]\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # batches\n","    for j in range(N // Nbatch):\n","\n","        indsBatch = range(j * Nbatch, (j+1) * Nbatch)\n","        X = Xtrain[indsBatch, :]\n","        Y = Ytrain[indsBatch, :]\n","\n","        # write the optimization algorithm on the batch (X,Y)\n","        # using the functions: loss_accuracy, sgd\n","        # the forward with the predict method from the model\n","        # and the backward function with autograd\n","\n","        Yhat = model(X)\n","        L, acc = loss_accuracy(loss, Yhat, Y)\n","        L.backward()\n","        model = sgd(model, eta)\n","\n","    ####################\n","    ##      END        #\n","    ####################\n","\n","\n","    Yhat_train = model(data.Xtrain)\n","    Yhat_test = model(data.Xtest)\n","    Ltrain, acctrain = loss_accuracy(loss, Yhat_train, data.Ytrain)\n","    Ltest, acctest = loss_accuracy(loss, Yhat_test, data.Ytest)\n","    Ygrid = model(data.Xgrid)  \n","\n","    title = 'Iter {}: Acc train {:.1f}% ({:.2f}), acc test {:.1f}% ({:.2f})'.format(iteration, acctrain, Ltrain, acctest, Ltest)\n","    print(title) \n","    data.plot_data_with_grid(torch.nn.Softmax(dim=1)(Ygrid.detach()), title)\n","\n","    curves[0].append(acctrain)\n","    curves[1].append(acctest)\n","    curves[2].append(Ltrain)\n","    curves[3].append(Ltest)\n","\n","fig = plt.figure()\n","plt.plot(curves[0], label=\"acc. train\")\n","plt.plot(curves[1], label=\"acc. test\")\n","plt.plot(curves[2], label=\"loss train\")\n","plt.plot(curves[3], label=\"loss test\")\n","plt.legend()\n","plt.show()"],"execution_count":111,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ViA5FjNb5zOB","executionInfo":{"status":"ok","timestamp":1635089298394,"user_tz":-120,"elapsed":212,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}},"outputId":"9664c76b-3cc2-4ad8-b0c6-125ff8ad8f7f"},"source":["#TESTS\n","j=0\n","Nbatch = 10\n","indsBatch = range(j * Nbatch, (j+1) * Nbatch)\n","model, loss = init_model(nx, nh, ny)\n","X = Xtrain[indsBatch, :]\n","Y = Ytrain[indsBatch, :]\n","\n","Yhat = model(X)\n","print(torch.max(Y,1)[1])\n","print(torch.max(Yhat,1)[1])\n","Y_ = torch.max(Y,1)[1]\n","loss(Yhat, Y_)"],"execution_count":93,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0, 0, 1, 1, 0, 1, 0, 0, 0, 1])\n","tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(0.7035, grad_fn=<NllLossBackward>)"]},"metadata":{},"execution_count":93}]},{"cell_type":"markdown","metadata":{"id":"GoFSrQNsJCnz"},"source":["# Part 4 : Simplification of the SGD with `torch.optim`"]},{"cell_type":"code","metadata":{"id":"S8WtN9loJPqP","executionInfo":{"status":"ok","timestamp":1635091559706,"user_tz":-120,"elapsed":294,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}}},"source":["def init_model(nx, nh, ny, eta):\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","\n","    model = torch.nn.Sequential(\n","        torch.nn.Linear(nx, nh),\n","        torch.nn.Tanh(),\n","        torch.nn.Linear(nh, ny)\n","    )\n","    loss = torch.nn.CrossEntropyLoss()\n","    optim = torch.optim.SGD(model.parameters(), lr=eta)\n","\n","    ####################\n","    ##      END        #\n","    ####################\n","\n","    return model, loss, optim"],"execution_count":114,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eY-0rRzPJYDd"},"source":["The `sgd` function is replaced by calling the `optim.zero_grad()` before the backward and `optim.step()` after. "]},{"cell_type":"markdown","metadata":{"id":"q82hCupvJxvV"},"source":["## Algorithme global d'apprentissage (avec autograd, les couches `torch.nn` et `torch.optim`)"]},{"cell_type":"code","metadata":{"id":"V9h9nINKJ1LU","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"17zF4q4w-kXd_aAxBV-U5HDN9uewIgVKV"},"executionInfo":{"status":"ok","timestamp":1635090407963,"user_tz":-120,"elapsed":44759,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}},"outputId":"24d1cc81-c8fb-4e46-8637-728a8bd7eff5"},"source":["# init\n","data = CirclesData()\n","data.plot_data()\n","N = data.Xtrain.shape[0]\n","Nbatch = 10\n","nx = data.Xtrain.shape[1]\n","nh = 10\n","ny = data.Ytrain.shape[1]\n","eta = 0.03\n","\n","model, loss, optim = init_model(nx, nh, ny, eta)\n","\n","curves = [[],[], [], []]\n","\n","# epoch\n","for iteration in range(150):\n","\n","    # permute\n","    perm = np.random.permutation(N)\n","    Xtrain = data.Xtrain[perm, :]\n","    Ytrain = data.Ytrain[perm, :]\n","\n","    #####################\n","    ## Your code  here ##\n","    #####################\n","    # batches\n","    for j in range(N // Nbatch):\n","\n","        indsBatch = range(j * Nbatch, (j+1) * Nbatch)\n","        X = Xtrain[indsBatch, :]\n","        Y = Ytrain[indsBatch, :]\n","  \n","        # write the optimization algorithm on the batch (X,Y)\n","        # using the functions: loss_accuracy\n","        # the forward with the predict method from the model\n","        # the backward function with autograd\n","        # and then an optimization step\n","\n","        Yhat = model(X)\n","        L, acc = loss_accuracy(loss, Yhat, Y)\n","        optim.zero_grad()\n","        L.backward()\n","        optim.step()\n","\n","\n","    ####################\n","    ##      FIN        #\n","    ####################\n","\n","\n","    Yhat_train = model(data.Xtrain)\n","    Yhat_test = model(data.Xtest)\n","    Ltrain, acctrain = loss_accuracy(loss, Yhat_train, data.Ytrain)\n","    Ltest, acctest = loss_accuracy(loss, Yhat_test, data.Ytest)\n","    Ygrid = model(data.Xgrid)  \n","\n","    title = 'Iter {}: Acc train {:.1f}% ({:.2f}), acc test {:.1f}% ({:.2f})'.format(iteration, acctrain, Ltrain, acctest, Ltest)\n","    print(title) \n","    data.plot_data_with_grid(torch.nn.Softmax(dim=1)(Ygrid.detach()), title)\n","\n","    curves[0].append(acctrain)\n","    curves[1].append(acctest)\n","    curves[2].append(Ltrain)\n","    curves[3].append(Ltest)\n","\n","fig = plt.figure()\n","plt.plot(curves[0], label=\"acc. train\")\n","plt.plot(curves[1], label=\"acc. test\")\n","plt.plot(curves[2], label=\"loss train\")\n","plt.plot(curves[3], label=\"loss test\")\n","plt.legend()\n","plt.show()"],"execution_count":104,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"Ts1s4JuOSaZ3"},"source":["# Part 5 : MNIST"]},{"cell_type":"markdown","metadata":{"id":"jly9C4FCSzLP"},"source":["Apply the code from previous part code to the MNIST dataset."]},{"cell_type":"code","metadata":{"id":"osrFoEr_Syi7","executionInfo":{"status":"ok","timestamp":1635091497882,"user_tz":-120,"elapsed":627,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}}},"source":["# init\n","data = MNISTData()\n","N = data.Xtrain.shape[0]\n","Nbatch = 100\n","nx = data.Xtrain.shape[1]\n","nh = 100\n","ny = data.Ytrain.shape[1]\n","eta = 0.03"],"execution_count":112,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"-BiCqFpMDE0H","executionInfo":{"status":"ok","timestamp":1635091871038,"user_tz":-120,"elapsed":285309,"user":{"displayName":"Célina Khalfat","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12319808006770558533"}},"outputId":"2bc206e6-1f9b-4e9c-ea7c-49e89f4749d5"},"source":["model, loss, optim = init_model(nx, nh, ny, eta)\n","\n","curves = [[],[], [], []]\n","\n","# epoch\n","for iteration in range(150):\n","\n","    # permute\n","    perm = np.random.permutation(N)\n","    Xtrain = data.Xtrain[perm, :]\n","    Ytrain = data.Ytrain[perm, :]\n","\n","    #####################\n","    ## Your code  here ##\n","    #####################\n","    # batches\n","    for j in range(N // Nbatch):\n","\n","        indsBatch = range(j * Nbatch, (j+1) * Nbatch)\n","        X = Xtrain[indsBatch, :]\n","        Y = Ytrain[indsBatch, :]\n","  \n","        # write the optimization algorithm on the batch (X,Y)\n","        # using the functions: loss_accuracy\n","        # the forward with the predict method from the model\n","        # the backward function with autograd\n","        # and then an optimization step\n","\n","        Yhat = model(X)\n","        L, acc = loss_accuracy(loss, Yhat, Y)\n","        optim.zero_grad()\n","        L.backward()\n","        optim.step()\n","\n","\n","    ####################\n","    ##      FIN        #\n","    ####################\n","\n","\n","    Yhat_train = model(data.Xtrain)\n","    Yhat_test = model(data.Xtest)\n","    Ltrain, acctrain = loss_accuracy(loss, Yhat_train, data.Ytrain)\n","    Ltest, acctest = loss_accuracy(loss, Yhat_test, data.Ytest)\n","\n","    title = 'Iter {}: Acc train {:.1f}% ({:.2f}), acc test {:.1f}% ({:.2f})'.format(iteration, acctrain, Ltrain, acctest, Ltest)\n","    print(title) \n","\n","    curves[0].append(acctrain)\n","    curves[1].append(acctest)\n","    curves[2].append(Ltrain)\n","    curves[3].append(Ltest)\n","\n","fig = plt.figure()\n","plt.plot(curves[0], label=\"acc. train\")\n","plt.plot(curves[1], label=\"acc. test\")\n","plt.plot(curves[2], label=\"loss train\")\n","plt.plot(curves[3], label=\"loss test\")\n","plt.legend()\n","plt.show()"],"execution_count":117,"outputs":[{"output_type":"stream","name":"stdout","text":["Iter 0: Acc train 0.8% (0.55), acc test 0.9% (0.53)\n","Iter 1: Acc train 0.9% (0.46), acc test 0.9% (0.45)\n","Iter 2: Acc train 0.9% (0.45), acc test 0.9% (0.44)\n","Iter 3: Acc train 0.9% (0.42), acc test 0.9% (0.40)\n","Iter 4: Acc train 0.9% (0.50), acc test 0.9% (0.48)\n","Iter 5: Acc train 0.9% (0.44), acc test 0.9% (0.43)\n","Iter 6: Acc train 0.9% (0.40), acc test 0.9% (0.38)\n","Iter 7: Acc train 0.9% (0.43), acc test 0.9% (0.42)\n","Iter 8: Acc train 0.9% (0.42), acc test 0.9% (0.41)\n","Iter 9: Acc train 0.9% (0.41), acc test 0.9% (0.41)\n","Iter 10: Acc train 0.9% (0.41), acc test 0.9% (0.40)\n","Iter 11: Acc train 0.9% (0.38), acc test 0.9% (0.38)\n","Iter 12: Acc train 0.9% (0.41), acc test 0.9% (0.41)\n","Iter 13: Acc train 0.9% (0.39), acc test 0.9% (0.38)\n","Iter 14: Acc train 0.9% (0.37), acc test 0.9% (0.36)\n","Iter 15: Acc train 0.9% (0.38), acc test 0.9% (0.38)\n","Iter 16: Acc train 0.9% (0.37), acc test 0.9% (0.35)\n","Iter 17: Acc train 0.9% (0.41), acc test 0.9% (0.39)\n","Iter 18: Acc train 0.9% (0.38), acc test 0.9% (0.37)\n","Iter 19: Acc train 0.9% (0.36), acc test 0.9% (0.34)\n","Iter 20: Acc train 0.9% (0.37), acc test 0.9% (0.37)\n","Iter 21: Acc train 0.9% (0.39), acc test 0.9% (0.39)\n","Iter 22: Acc train 0.9% (0.36), acc test 0.9% (0.35)\n","Iter 23: Acc train 0.9% (0.38), acc test 0.9% (0.38)\n","Iter 24: Acc train 0.9% (0.37), acc test 0.9% (0.36)\n","Iter 25: Acc train 0.9% (0.37), acc test 0.9% (0.36)\n","Iter 26: Acc train 0.9% (0.34), acc test 0.9% (0.33)\n","Iter 27: Acc train 0.9% (0.36), acc test 0.9% (0.36)\n","Iter 28: Acc train 0.9% (0.34), acc test 0.9% (0.33)\n","Iter 29: Acc train 0.9% (0.33), acc test 0.9% (0.32)\n","Iter 30: Acc train 0.9% (0.33), acc test 0.9% (0.33)\n","Iter 31: Acc train 0.9% (0.33), acc test 0.9% (0.33)\n","Iter 32: Acc train 0.9% (0.32), acc test 0.9% (0.33)\n","Iter 33: Acc train 0.9% (0.31), acc test 0.9% (0.32)\n","Iter 34: Acc train 0.9% (0.32), acc test 0.9% (0.33)\n","Iter 35: Acc train 0.9% (0.31), acc test 0.9% (0.31)\n","Iter 36: Acc train 0.9% (0.32), acc test 0.9% (0.33)\n","Iter 37: Acc train 0.9% (0.32), acc test 0.9% (0.32)\n","Iter 38: Acc train 0.9% (0.31), acc test 0.9% (0.31)\n","Iter 39: Acc train 0.9% (0.31), acc test 0.9% (0.30)\n","Iter 40: Acc train 0.9% (0.32), acc test 0.9% (0.31)\n","Iter 41: Acc train 0.9% (0.30), acc test 0.9% (0.30)\n","Iter 42: Acc train 0.9% (0.30), acc test 0.9% (0.30)\n","Iter 43: Acc train 0.9% (0.32), acc test 0.9% (0.32)\n","Iter 44: Acc train 0.9% (0.30), acc test 0.9% (0.29)\n","Iter 45: Acc train 0.9% (0.29), acc test 0.9% (0.28)\n","Iter 46: Acc train 0.9% (0.31), acc test 0.9% (0.32)\n","Iter 47: Acc train 0.9% (0.31), acc test 0.9% (0.31)\n","Iter 48: Acc train 0.9% (0.30), acc test 0.9% (0.30)\n","Iter 49: Acc train 0.9% (0.31), acc test 0.9% (0.31)\n","Iter 50: Acc train 0.9% (0.30), acc test 0.9% (0.31)\n","Iter 51: Acc train 0.9% (0.30), acc test 0.9% (0.31)\n","Iter 52: Acc train 0.9% (0.31), acc test 0.9% (0.31)\n","Iter 53: Acc train 0.9% (0.30), acc test 0.9% (0.30)\n","Iter 54: Acc train 0.9% (0.29), acc test 0.9% (0.28)\n","Iter 55: Acc train 0.9% (0.29), acc test 0.9% (0.30)\n","Iter 56: Acc train 0.9% (0.31), acc test 0.9% (0.30)\n","Iter 57: Acc train 0.9% (0.27), acc test 0.9% (0.27)\n","Iter 58: Acc train 0.9% (0.28), acc test 0.9% (0.29)\n","Iter 59: Acc train 0.9% (0.27), acc test 0.9% (0.27)\n","Iter 60: Acc train 0.9% (0.28), acc test 0.9% (0.28)\n","Iter 61: Acc train 0.9% (0.28), acc test 0.9% (0.27)\n","Iter 62: Acc train 0.9% (0.26), acc test 0.9% (0.26)\n","Iter 63: Acc train 0.9% (0.27), acc test 0.9% (0.27)\n","Iter 64: Acc train 0.9% (0.29), acc test 0.9% (0.29)\n","Iter 65: Acc train 0.9% (0.26), acc test 0.9% (0.25)\n","Iter 66: Acc train 0.9% (0.25), acc test 0.9% (0.24)\n","Iter 67: Acc train 0.9% (0.26), acc test 0.9% (0.26)\n","Iter 68: Acc train 0.9% (0.26), acc test 0.9% (0.25)\n","Iter 69: Acc train 0.9% (0.26), acc test 0.9% (0.26)\n","Iter 70: Acc train 0.9% (0.26), acc test 0.9% (0.25)\n","Iter 71: Acc train 0.9% (0.25), acc test 0.9% (0.25)\n","Iter 72: Acc train 0.9% (0.26), acc test 0.9% (0.26)\n","Iter 73: Acc train 0.9% (0.26), acc test 0.9% (0.27)\n","Iter 74: Acc train 0.9% (0.27), acc test 0.9% (0.28)\n","Iter 75: Acc train 0.9% (0.25), acc test 0.9% (0.26)\n","Iter 76: Acc train 0.9% (0.25), acc test 0.9% (0.26)\n","Iter 77: Acc train 0.9% (0.24), acc test 0.9% (0.25)\n","Iter 78: Acc train 0.9% (0.26), acc test 0.9% (0.26)\n","Iter 79: Acc train 0.9% (0.25), acc test 0.9% (0.26)\n","Iter 80: Acc train 0.9% (0.25), acc test 0.9% (0.26)\n","Iter 81: Acc train 0.9% (0.25), acc test 0.9% (0.25)\n","Iter 82: Acc train 0.9% (0.28), acc test 0.9% (0.29)\n","Iter 83: Acc train 0.9% (0.26), acc test 0.9% (0.26)\n","Iter 84: Acc train 0.9% (0.23), acc test 0.9% (0.23)\n","Iter 85: Acc train 0.9% (0.25), acc test 0.9% (0.26)\n","Iter 86: Acc train 0.9% (0.26), acc test 0.9% (0.27)\n","Iter 87: Acc train 0.9% (0.27), acc test 0.9% (0.28)\n","Iter 88: Acc train 0.9% (0.27), acc test 0.9% (0.27)\n","Iter 89: Acc train 0.9% (0.26), acc test 0.9% (0.26)\n","Iter 90: Acc train 0.9% (0.27), acc test 0.9% (0.28)\n","Iter 91: Acc train 0.9% (0.25), acc test 0.9% (0.27)\n","Iter 92: Acc train 0.9% (0.26), acc test 0.9% (0.27)\n","Iter 93: Acc train 0.9% (0.24), acc test 0.9% (0.26)\n","Iter 94: Acc train 0.9% (0.24), acc test 0.9% (0.25)\n","Iter 95: Acc train 0.9% (0.24), acc test 0.9% (0.25)\n","Iter 96: Acc train 0.9% (0.24), acc test 0.9% (0.25)\n","Iter 97: Acc train 0.9% (0.25), acc test 0.9% (0.26)\n","Iter 98: Acc train 0.9% (0.23), acc test 0.9% (0.25)\n","Iter 99: Acc train 0.9% (0.23), acc test 0.9% (0.25)\n","Iter 100: Acc train 0.9% (0.23), acc test 0.9% (0.24)\n","Iter 101: Acc train 0.9% (0.24), acc test 0.9% (0.24)\n","Iter 102: Acc train 0.9% (0.22), acc test 0.9% (0.24)\n","Iter 103: Acc train 0.9% (0.24), acc test 0.9% (0.26)\n","Iter 104: Acc train 0.9% (0.25), acc test 0.9% (0.26)\n","Iter 105: Acc train 0.9% (0.22), acc test 0.9% (0.24)\n","Iter 106: Acc train 0.9% (0.23), acc test 0.9% (0.24)\n","Iter 107: Acc train 0.9% (0.23), acc test 0.9% (0.24)\n","Iter 108: Acc train 0.9% (0.23), acc test 0.9% (0.24)\n","Iter 109: Acc train 0.9% (0.25), acc test 0.9% (0.26)\n","Iter 110: Acc train 0.9% (0.23), acc test 0.9% (0.24)\n","Iter 111: Acc train 0.9% (0.23), acc test 0.9% (0.24)\n","Iter 112: Acc train 0.9% (0.24), acc test 0.9% (0.24)\n","Iter 113: Acc train 0.9% (0.24), acc test 0.9% (0.24)\n","Iter 114: Acc train 0.9% (0.24), acc test 0.9% (0.25)\n","Iter 115: Acc train 0.9% (0.24), acc test 0.9% (0.25)\n","Iter 116: Acc train 0.9% (0.24), acc test 0.9% (0.24)\n","Iter 117: Acc train 0.9% (0.22), acc test 0.9% (0.23)\n","Iter 118: Acc train 0.9% (0.23), acc test 0.9% (0.23)\n","Iter 119: Acc train 0.9% (0.23), acc test 0.9% (0.24)\n","Iter 120: Acc train 0.9% (0.23), acc test 0.9% (0.24)\n","Iter 121: Acc train 0.9% (0.23), acc test 0.9% (0.25)\n","Iter 122: Acc train 0.9% (0.22), acc test 0.9% (0.24)\n","Iter 123: Acc train 0.9% (0.24), acc test 0.9% (0.25)\n","Iter 124: Acc train 0.9% (0.25), acc test 0.9% (0.26)\n","Iter 125: Acc train 0.9% (0.24), acc test 0.9% (0.25)\n","Iter 126: Acc train 0.9% (0.22), acc test 0.9% (0.24)\n","Iter 127: Acc train 0.9% (0.23), acc test 0.9% (0.23)\n","Iter 128: Acc train 0.9% (0.22), acc test 0.9% (0.22)\n","Iter 129: Acc train 0.9% (0.22), acc test 0.9% (0.22)\n","Iter 130: Acc train 0.9% (0.22), acc test 0.9% (0.23)\n","Iter 131: Acc train 0.9% (0.23), acc test 0.9% (0.23)\n","Iter 132: Acc train 0.9% (0.21), acc test 0.9% (0.22)\n","Iter 133: Acc train 0.9% (0.21), acc test 0.9% (0.22)\n","Iter 134: Acc train 0.9% (0.24), acc test 0.9% (0.24)\n","Iter 135: Acc train 0.9% (0.23), acc test 0.9% (0.23)\n","Iter 136: Acc train 0.9% (0.23), acc test 0.9% (0.23)\n","Iter 137: Acc train 0.9% (0.23), acc test 0.9% (0.24)\n","Iter 138: Acc train 0.9% (0.22), acc test 0.9% (0.23)\n","Iter 139: Acc train 0.9% (0.23), acc test 0.9% (0.23)\n","Iter 140: Acc train 0.9% (0.22), acc test 0.9% (0.22)\n","Iter 141: Acc train 0.9% (0.21), acc test 0.9% (0.22)\n","Iter 142: Acc train 0.9% (0.22), acc test 0.9% (0.22)\n","Iter 143: Acc train 0.9% (0.22), acc test 0.9% (0.22)\n","Iter 144: Acc train 0.9% (0.21), acc test 0.9% (0.22)\n","Iter 145: Acc train 0.9% (0.22), acc test 0.9% (0.24)\n","Iter 146: Acc train 0.9% (0.23), acc test 0.9% (0.24)\n","Iter 147: Acc train 0.9% (0.24), acc test 0.9% (0.25)\n","Iter 148: Acc train 0.9% (0.23), acc test 0.9% (0.25)\n","Iter 149: Acc train 0.9% (0.24), acc test 0.9% (0.26)\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"YRoiGbhvmSLO"},"source":["# Part 6: Bonus: SVM\n","\n","\n","Train a SVM model on the Circles dataset.\n","\n","Ideas : \n","- First try a linear SVM (sklearn.svm.LinearSVC dans scikit-learn). Does it work well ? Why ?\n","- Then try more complex kernels (sklearn.svm.SVC). Which one is the best ? why ?\n","- Does the parameter C of regularization have an impact? Why ?"]},{"cell_type":"code","metadata":{"id":"VWeW8siymR3g"},"source":["# data\n","data = CirclesData()\n","Xtrain = data.Xtrain.numpy()\n","Ytrain = data.Ytrain[:, 0].numpy()\n","\n","Xgrid = data.Xgrid.numpy()\n","\n","Xtest = data.Xtest.numpy()\n","Ytest = data.Ytest[:, 0].numpy()\n","\n","def plot_svm_predictions(data, predictions):\n","      plt.figure(2)\n","      plt.clf()\n","      plt.imshow(np.reshape(predictions, (40,40)))\n","      plt.plot(data._Xtrain[data._Ytrain[:,0] == 1,0]*10+20, data._Xtrain[data._Ytrain[:,0] == 1,1]*10+20, 'bo', label=\"Train\")\n","      plt.plot(data._Xtrain[data._Ytrain[:,1] == 1,0]*10+20, data._Xtrain[data._Ytrain[:,1] == 1,1]*10+20, 'ro')\n","      plt.plot(data._Xtest[data._Ytest[:,0] == 1,0]*10+20, data._Xtest[data._Ytest[:,0] == 1,1]*10+20, 'b+', label=\"Test\")\n","      plt.plot(data._Xtest[data._Ytest[:,1] == 1,0]*10+20, data._Xtest[data._Ytest[:,1] == 1,1]*10+20, 'r+')\n","      plt.xlim(0,39)\n","      plt.ylim(0,39)\n","      plt.clim(0.3,0.7)\n","      plt.draw()\n","      plt.pause(1e-3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e1xcE6zbmXU1"},"source":["import sklearn.svm\n","\n","############################\n","### Your code here   #######\n","### Train the SVM    #######\n","## See https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n","## and https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n","############################\n","\n","svm = None\n","\n","###########################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vgLl7B_3mbOs"},"source":["## Print results\n","\n","Ytest_pred = svm.predict(Xtest)\n","accuracy = np.sum(Ytest == Ytest_pred) / len(Ytest)\n","print(f\"Accuracy : {100 * accuracy:.2f}\")\n","Ygrid_pred = svm.predict(Xgrid)\n","plot_svm_predictions(data, Ygrid_pred)"],"execution_count":null,"outputs":[]}]}